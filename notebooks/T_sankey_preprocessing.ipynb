{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core import display as ICD\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer\n",
    "from itertools import groupby, product\n",
    "import json\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcm_output(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z) for z in x.split(\" \") if z != \"\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_lcm_output_total(input_name,folder=\"../lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : [int(z.replace('\"',\"\")) for z in x[1:-1].split(\",\") if z != \"\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for echarts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_descriptions(x,items,encoder):\n",
    "    if isinstance(x,int):\n",
    "        x = \"[x]\n",
    "    ee = encoder.inverse_transform([int(i) for i in x.split()])\n",
    "    return items.loc[items.index.isin(ee)].DESCRIPTION.tolist()\n",
    "def format_links(x):\n",
    "    res = []\n",
    "    for i in x[0]:\n",
    "        for idx in range(len(i)-1):\n",
    "            res.append([i[idx],i[idx+1],x[\"index\"]])\n",
    "    return res\n",
    "\n",
    "def make_links(e,index):\n",
    "    \"\"\"Product of groups ids for each two consecutive groups periods\"\"\"\n",
    "    prev = e[0]\n",
    "    for i in e[1:]:\n",
    "        yield from product(prev,i,[index])\n",
    "        prev = i\n",
    "\n",
    "def extract_demographics(input_file):\n",
    "    demographics = re.findall(\"\\[([A-Z|a-z|_]+),?([A-Z|a-z|_]+)?\\]\",input_file)[0]\n",
    "    return  [i for i in demographics if i !=\"\"]\n",
    "    \n",
    "def sankey_preprocessing(input_file,stats_folder='../plots/stats',encoders_folder=\"../plots/encoders\",links_folder=\"../plots/links\",groups_folder='../plots/groups',users_demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"],groups_demographics=[\"STATION_MGT_TYPE\",\"DEPARTEMENT\"],user_apparition_threshold=0,user_nunique_periods_threshold=3,keep_all_groups_in_periods=[]):\n",
    "\n",
    "    demographics = extract_demographics(input_file)\n",
    "    users = pd.read_csv(\"../datasets/Total/users.csv\",sep=\";\")\n",
    "    df = read_lcm_output_total(input_file).sort_values(\"period\").reset_index(drop=True)\n",
    "    \n",
    "    file = f'../plots/links/{input_file}'\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    _df = mlb.fit_transform(df.user_ids.tolist()).astype(bool)\n",
    "    _df = pd.DataFrame(_df.toarray(),columns=mlb.classes_)\n",
    "    \n",
    "    e = _df.sum()\n",
    "    _df = _df[e[e>user_apparition_threshold].index] \n",
    "    _df  = _df.T.apply(lambda x : np.where(x)[0],axis=1)\n",
    "    e = _df.to_frame()[0].apply(lambda x: list(list(z) for idx,z in groupby(x,lambda y: df.iloc[y].period)))\n",
    "    e = e[e.apply(lambda x:len(x))>user_nunique_periods_threshold]\n",
    "    \n",
    "    res = []\n",
    "    e.to_frame().reset_index().apply(lambda x: [res.append(i) for i in make_links(x[0],x[\"index\"])],axis=1)\n",
    "    links = pd.DataFrame(res)\n",
    "  \n",
    "\n",
    "    links.columns = [\"source\",\"target\",\"user_id\"]\n",
    "    links.groupby([\"source\",\"target\"])[\"user_id\"].apply(lambda x: ','.join(str(i) for i in x)).to_frame().to_csv(file)\n",
    "\n",
    "#     # Users demographics stats  \n",
    "#     file = f'../plots/stats/users/{input_file}'\n",
    "#     stats = {}\n",
    "#     users_stats = links[[\"user_id\"]].drop_duplicates().merge(users,left_on=\"user_id\",right_on=\"CUST_ID\")[users.columns]\n",
    "#     for i in users_demographics:\n",
    "#         b = users_stats.groupby(i).apply(lambda x: {\"name\":x[i].unique()[0],\"value\":x.CUST_ID.shape[0],\"users\":\",\".join(str(i) for i in x.CUST_ID)}).values\n",
    "#         stats[i] = b.tolist()\n",
    "        \n",
    "#     with open(file, 'w') as outfile:\n",
    "#         json.dump(stats, outfile)\n",
    "  \n",
    "    \n",
    "#     # Users\n",
    "#     file = f'../plots/users/{input_file}'\n",
    "#     users_stats.to_csv(file)\n",
    "    \n",
    "    # filter groups to the ones appearing in the links\n",
    "    file = f'{groups_folder}/{input_file}'\n",
    "    groups_to_keep = np.unique(np.union1d(links.source.unique(),links.target.unique()))\n",
    "\n",
    "    groups_to_keep = np.union1d(groups_to_keep,df[df.period.isin(keep_all_groups_in_periods)].index)\n",
    "    df_reduced_filtred = df.loc[groups_to_keep].dropna()\n",
    "    \n",
    "    df_reduced_filtred['depth'] = le.fit_transform(df_reduced_filtred.period)/df_reduced_filtred.period.nunique()\n",
    "    df_reduced_filtred['size'] = df_reduced_filtred.user_ids.apply(lambda x : len(x))\n",
    "    if len(demographics)==1:\n",
    "        df_reduced_filtred[demographics[0]]= df_reduced_filtred.property_values\n",
    "    else:\n",
    "        df_reduced_filtred[demographics]= df_reduced_filtred.property_values.str.split(\"_\",expand=True)\n",
    "    \n",
    "    # Encoding items to their initial ID + adding names\n",
    "    items = pd.read_csv(\"../datasets/Total/items.csv\")\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load(f'{encoders_folder}/15D-3-[2-5000]-[AGE]-lcm.out.npy')\n",
    "    items = items.set_index(\"ARTICLE_ID\")\n",
    "    df_reduced_filtred[\"itemset_name\"] = df_reduced_filtred[\"itemsets\"].apply(lambda x : get_articles_descriptions(x,items,encoder))\n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    \n",
    "    # Groups demographics stats \n",
    "    file = f'../plots/stats/groups/{input_file}'\n",
    "    stats = {}\n",
    "    for i in np.intersect1d(groups_demographics,demographics):\n",
    "        b = df_reduced_filtred.groupby(i).apply(lambda x : {\"name\":x[i].unique()[0],\"value\":x.index.shape[0],\"groups\":\",\".join(str(i) for i in x.index)}).values\n",
    "        stats[i]=str(b.tolist())\n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "\n",
    "    print(\"Done\",input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2M-20-[1-None]-[a]-lcm.out ['a']\n",
      "4125\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c4d71f2eb1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextract_demographics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msankey_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_all_groups_in_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-88f3b7183a0a>\u001b[0m in \u001b[0;36msankey_preprocessing\u001b[0;34m(input_file, stats_folder, encoders_folder, links_folder, groups_folder, users_demographics, groups_demographics, user_apparition_threshold, user_nunique_periods_threshold, keep_all_groups_in_periods)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{encoders_folder}/15D-3-[2-5000]-[AGE]-lcm.out.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ARTICLE_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itemset_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itemsets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mget_articles_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/3env/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-88f3b7183a0a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{encoders_folder}/15D-3-[2-5000]-[AGE]-lcm.out.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ARTICLE_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itemset_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itemsets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mget_articles_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mdf_reduced_filtred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-88f3b7183a0a>\u001b[0m in \u001b[0;36mget_articles_descriptions\u001b[0;34m(x, items, encoder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_articles_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDESCRIPTION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformat_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "input_file = \"2M-20-[1-None]-[a]-lcm.out\"\n",
    "for i in [input_file]:\n",
    "    print(i,extract_demographics(i))\n",
    "    e = sankey_preprocessing(i,keep_all_groups_in_periods=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done M-2-[1-None]-[SEX]-lcm.out\n"
     ]
    }
   ],
   "source": [
    "sankey_preprocessing(\"M-2-[1-None]-[SEX]-lcm.out\",user_nunique_periods_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [114621, 123927, 139931, 147495, 154330, 16898...\n",
       "1                       [419062, 448392, 552027, 1058591]\n",
       "2               [419062, 448392, 552027, 562198, 1058591]\n",
       "3       [199673, 247735, 277744, 453671, 555714, 59744...\n",
       "4                     [522344, 1036452, 1045705, 1082751]\n",
       "                              ...                        \n",
       "1060             [111931, 172631, 218865, 268731, 275156]\n",
       "1061             [267234, 268731, 443377, 488580, 568735]\n",
       "1062    [140231, 194407, 210460, 242618, 287308, 28773...\n",
       "1063     [336312, 337630, 338619, 374604, 404236, 752568]\n",
       "1064                     [209988, 524542, 753456, 901254]\n",
       "Name: user_ids, Length: 1065, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file =\"M-2-[1-None]-[SEX]-lcm.out\"\n",
    "df = read_lcm_output_total(input_file).sort_values(\"period\").reset_index(drop=True)\n",
    "df.user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sankey preprocessing updating new file instead of creating from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sankey_preprocessing(old_output,input_file,stats_folder='../plots/stats',encoders_folder=\"../plots/encoders\",links_folder=\"../plots/links\",groups_folder='../plots/groups',users_demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"],groups_demographics=[\"STATION_MGT_TYPE\",\"DEPARTEMENT\"],user_apparition_threshold=0,user_nunique_periods_threshold=3,keep_all_groups_in_periods=[]):\n",
    "\n",
    "    demographics = extract_demographics(input_file)\n",
    "    users = pd.read_csv(\"../datasets/Total/users.csv\",sep=\";\")\n",
    "    df = read_lcm_output_total(input_file).sort_values(\"period\").reset_index(drop=True)\n",
    "    \n",
    "    file = f'../plots/links/{input_file}'\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    _df = mlb.fit_transform(df.user_ids.tolist()).astype(bool)\n",
    "    _df = pd.DataFrame(_df.toarray(),columns=mlb.classes_)\n",
    "    \n",
    "    e = _df.sum()\n",
    "    _df = _df[e[e>user_apparition_threshold].index] \n",
    "    _df  = _df.T.apply(lambda x : np.where(x)[0],axis=1)\n",
    "    e = _df.to_frame()[0].apply(lambda x: list(list(z) for idx,z in groupby(x,lambda y: df.iloc[y].period)))\n",
    "    e = e[e.apply(lambda x:len(x))>user_nunique_periods_threshold]\n",
    "    \n",
    "    res = []\n",
    "    e.to_frame().reset_index().apply(lambda x: [res.append(i) for i in make_links(x[0],x[\"index\"])],axis=1)\n",
    "    links = pd.DataFrame(res)\n",
    "  \n",
    "\n",
    "    links.columns = [\"source\",\"target\",\"user_id\"]\n",
    "    links.groupby([\"source\",\"target\"])[\"user_id\"].apply(lambda x: ','.join(str(i) for i in x)).to_frame().to_csv(file)\n",
    "\n",
    "    # filter groups to the ones appearing in the links\n",
    "    file = f'{groups_folder}/{input_file}'\n",
    "    groups_to_keep = np.unique(np.union1d(links.source.unique(),links.target.unique()))\n",
    "\n",
    "    groups_to_keep = np.union1d(groups_to_keep,df[df.period.isin(keep_all_groups_in_periods)].index)\n",
    "    df_reduced_filtred = df.loc[groups_to_keep].dropna()\n",
    "    \n",
    "    df_reduced_filtred['depth'] = le.fit_transform(df_reduced_filtred.period)/df_reduced_filtred.period.nunique()\n",
    "    df_reduced_filtred['size'] = df_reduced_filtred.user_ids.apply(lambda x : len(x))\n",
    "    if len(demographics)==1:\n",
    "        df_reduced_filtred[demographics[0]]= df_reduced_filtred.property_values\n",
    "    else:\n",
    "        df_reduced_filtred[demographics]= df_reduced_filtred.property_values.str.split(\"_\",expand=True)\n",
    "    \n",
    "    # Encoding items to their initial ID + adding names\n",
    "    items = pd.read_csv(\"../datasets/Total/items.csv\")\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load(f'{encoders_folder}/15D-3-[2-5000]-[AGE]-lcm.out.npy')\n",
    "    items = items.set_index(\"ARTICLE_ID\")\n",
    "    df_reduced_filtred[\"itemset_name\"] = df_reduced_filtred[\"itemsets\"].apply(lambda x : get_articles_descriptions(x,items,encoder))\n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    \n",
    "#     # Groups demographics stats \n",
    "#     file = f'../plots/stats/groups/{input_file}'\n",
    "#     stats = {}\n",
    "#     for i in np.intersect1d(groups_demographics,demographics):\n",
    "#         b = df_reduced_filtred.groupby(i).apply(lambda x : {\"name\":x[i].unique()[0],\"value\":x.index.shape[0],\"groups\":\",\".join(str(i) for i in x.index)}).values\n",
    "#         stats[i]=str(b.tolist())\n",
    "#     with open(file, 'w') as outfile:\n",
    "#         json.dump(stats, outfile)\n",
    "\n",
    "    print(\"Done\",input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-29c41fa7b1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_lcm_output_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"period\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "df = read_lcm_output_total(output_file).sort_values(\"period\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
