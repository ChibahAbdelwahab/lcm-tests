{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core import display as ICD\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer\n",
    "from itertools import groupby, product\n",
    "import json\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcm_output(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z) for z in x.split(\" \") if z != \"\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_lcm_output_total(input_name,folder=\"../lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : [int(z.replace('\"',\"\")) for z in x[1:-1].split(\",\") if z != \"\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for echarts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_descriptions(x,items,encoder):\n",
    "    ee = encoder.inverse_transform([int(i) for i in x.split()])\n",
    "    return items.loc[items.index.isin(ee)].DESCRIPTION.tolist()\n",
    "def format_links(x):\n",
    "    res = []\n",
    "    for i in x[0]:\n",
    "        for idx in range(len(i)-1):\n",
    "            res.append([i[idx],i[idx+1],x[\"index\"]])\n",
    "    return res\n",
    "\n",
    "def make_links(e,index):\n",
    "    \"\"\"Product of groups ids for each two consecutive groups periods\"\"\"\n",
    "    prev = e[0]\n",
    "    for i in e[1:]:\n",
    "        yield from product(prev,i,[index])\n",
    "        prev = i\n",
    "\n",
    "def extract_demographics(input_file):\n",
    "    demographics = re.findall(\"\\[([A-Z|a-z|_]+),?([A-Z|a-z|_]+)?\\]\",input_file)[0]\n",
    "    return  [i for i in demographics if i !=\"\"]\n",
    "    \n",
    "def sankey_preprocessing(input_file,stats_folder='../plots/stats',encoders_folder=\"../plots/encoders\",links_folder=\"../plots/links\",groups_folder='../plots/groups',users_demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"],groups_demographics=[\"STATION_MGT_TYPE\",\"DEPARTEMENT\"],users_consecutive_apparition=3,keep_all_groups_in_periods=[]):\n",
    "\n",
    "    demographics = extract_demographics(input_file)\n",
    "    users = pd.read_csv(\"../datasets/Total/users.csv\",sep=\";\")\n",
    "    df = read_lcm_output_total(input_file).sort_values(\"period\").reset_index(drop=True)\n",
    "    \n",
    "    file = f'../plots/links/{input_file}'\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    _df = mlb.fit_transform(df.user_ids.tolist()).astype(bool)\n",
    "    _df = pd.DataFrame(_df.toarray(),columns=mlb.classes_)\n",
    "    \n",
    "    e = _df.sum()\n",
    "    _df = _df[e[e>0].index] \n",
    "    _df  = _df.T.apply(lambda x : np.where(x)[0],axis=1)\n",
    "    e = _df.to_frame()[0].apply(lambda x: list(list(z) for idx,z in groupby(x,lambda y: df.iloc[y].period)))\n",
    "    e = e[e.apply(lambda x:len(x))>users_consecutive_apparition]\n",
    "    \n",
    "    res = []\n",
    "    e.to_frame().reset_index().apply(lambda x: [res.append(i) for i in make_links(x[0],x[\"index\"])],axis=1)\n",
    "    links = pd.DataFrame(res)\n",
    "    links.columns = [\"source\",\"target\",\"user_id\"]\n",
    "    links.groupby([\"source\",\"target\"])[\"user_id\"].apply(lambda x: ','.join(str(i) for i in x)).to_frame().to_csv(file)\n",
    "\n",
    "    # Users demographics stats  \n",
    "    file = f'../plots/stats/users/{input_file}'\n",
    "    stats = {}\n",
    "    users_stats = links[[\"user_id\"]].drop_duplicates().merge(users,left_on=\"user_id\",right_on=\"CUST_ID\")[users.columns]\n",
    "    for i in users_demographics:\n",
    "        b = users_stats.groupby(i).apply(lambda x: {\"name\":x[i].unique()[0],\"value\":x.CUST_ID.shape[0],\"users\":\",\".join(str(i) for i in x.CUST_ID)}).values\n",
    "        stats[i] = b.tolist()\n",
    "        \n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "  \n",
    "    \n",
    "    # Users\n",
    "    file = f'../plots/users/{input_file}'\n",
    "    users_stats.to_csv(file)\n",
    "    \n",
    "    # filter groups to the ones appearing in the links\n",
    "    file = f'{groups_folder}/{input_file}'\n",
    "    groups_to_keep = np.unique(np.union1d(links.source.unique(),links.target.unique()))\n",
    "\n",
    "    groups_to_keep = np.union1d(groups_to_keep,df[df.period.isin(keep_all_groups_in_periods)].index)\n",
    "    df_reduced_filtred = df.loc[groups_to_keep].dropna()\n",
    "    \n",
    "    df_reduced_filtred['depth'] = le.fit_transform(df_reduced_filtred.period)/df_reduced_filtred.period.nunique()\n",
    "    df_reduced_filtred['size'] = df_reduced_filtred.user_ids.apply(lambda x : len(x))\n",
    "    if len(demographics)==1:\n",
    "        df_reduced_filtred[demographics[0]]= df_reduced_filtred.property_values\n",
    "    else:\n",
    "        df_reduced_filtred[demographics]= df_reduced_filtred.property_values.str.split(\"_\",expand=True)\n",
    "    \n",
    "    # Encoding items to their initial ID + adding names\n",
    "    items = pd.read_csv(\"../datasets/Total/items.csv\")\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load(f'{encoders_folder}/{input_file}.npy')\n",
    "    items = items.set_index(\"ARTICLE_ID\")\n",
    "    df_reduced_filtred[\"itemset_name\"] = df_reduced_filtred[\"itemsets\"].apply(lambda x : get_articles_descriptions(x,items,encoder))\n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    # Groups demographics stats \n",
    "    file = f'../plots/stats/groups/{input_file}'\n",
    "    stats = {}\n",
    "    for i in np.intersect1d(groups_demographics,demographics):\n",
    "        b = df_reduced_filtred.groupby(i).apply(lambda x : {\"name\":x[i].unique()[0],\"value\":x.index.shape[0],\"groups\":\",\".join(str(i) for i in x.index)}).values\n",
    "        stats[i]=str(b.tolist())\n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "\n",
    "    print(\"Done\",input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9M-5-[1-2001]-[a]-lcm.out ['a']\n",
      "Done 9M-5-[1-2001]-[a]-lcm.out\n"
     ]
    }
   ],
   "source": [
    "input_file = \"9M-5-[1-2001]-[a]-lcm.out\"\n",
    "for i in [\"9M-5-[1-2001]-[a]-lcm.out\"]:\n",
    "    print(i,extract_demographics(i))\n",
    "    e = sankey_preprocessing(i,users_consecutive_apparition=2,keep_all_groups_in_periods=[\"2018-12-01\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../datasets/Total/items.csv\")\n",
    "# encoder = LabelEncoder()\n",
    "# encoders_folder=\"../plots/encoders\"\n",
    "# encoder.classes_ = np.load(f'{encoders_folder}/{input_file}.npy')\n",
    "# items.ARTICLE_ID.as\n",
    "# items = items.set_index(\"ARTICLE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1574    False\n",
       "1575    False\n",
       "1576    False\n",
       "1577    False\n",
       "1578    False\n",
       "Name: period, Length: 1579, dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_all_groups_in_periods=[\"2019-12-01\"]\n",
    "(e.period==\"2019-12-01\").s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ids</th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "      <th>period</th>\n",
       "      <th>property_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>[153673, 197039, 221102, 408597, 508399, 58429...</td>\n",
       "      <td>9</td>\n",
       "      <td>4127</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>[191426, 230856, 258533, 322922, 424651, 57272...</td>\n",
       "      <td>10</td>\n",
       "      <td>4133</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>[218744, 293559, 493932, 875750, 1010670]</td>\n",
       "      <td>5</td>\n",
       "      <td>2200</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>[103316, 107231, 110754, 113725, 113895, 11444...</td>\n",
       "      <td>185</td>\n",
       "      <td>4186</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>[101105, 124784, 171396, 189197, 199984, 20903...</td>\n",
       "      <td>40</td>\n",
       "      <td>4120</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>[101392, 102917, 103904, 105649, 105769, 10787...</td>\n",
       "      <td>740</td>\n",
       "      <td>4175</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              user_ids  support itemsets  \\\n",
       "780  [153673, 197039, 221102, 408597, 508399, 58429...        9     4127   \n",
       "781  [191426, 230856, 258533, 322922, 424651, 57272...       10     4133   \n",
       "782          [218744, 293559, 493932, 875750, 1010670]        5     2200   \n",
       "783  [103316, 107231, 110754, 113725, 113895, 11444...      185     4186   \n",
       "784  [101105, 124784, 171396, 189197, 199984, 20903...       40     4120   \n",
       "785  [101392, 102917, 103904, 105649, 105769, 10787...      740     4175   \n",
       "\n",
       "        period  property_values  \n",
       "780 2018-12-01                1  \n",
       "781 2018-12-01                1  \n",
       "782 2018-12-01                1  \n",
       "783 2018-12-01                1  \n",
       "784 2018-12-01                1  \n",
       "785 2018-12-01                1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[e.period=='2018-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
