{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LsphgaVBzCv"
   },
   "source": [
    "# LCM Miner tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EQ_RoU1ZBzCx",
    "outputId": "25b0ce14-bc89-436b-c6a0-9529b016e369"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import date,datetime\n",
    "import csv\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "from IPython.core import display as ICD\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6274hWRBzC1"
   },
   "source": [
    "### 1. Une fonction qui prend les arguments suivants:\n",
    "jeu de données (contenant timestamp)\n",
    "fréquence de temps choisie (année, mois, jour) et qui retourne le jeu de données partitionné selon la granularité temporelle sous la forme de plusieurs fichiers, un par couple (partition, période de temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxosfaoHBzC2"
   },
   "outputs": [],
   "source": [
    "# TODO dateset_filter parameter not used\n",
    "def split_dataset(input_file,frequency,dataset_filter):\n",
    "    \"\"\"Split initial dataset to multiple files according to frequency\n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    str\n",
    "        names of partitions files\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "#     df.query(dataset_filter,inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],unit=\"s\").dt.to_period(frequency)\n",
    "    df.set_index([\"timestamp\"],inplace=True)\n",
    "    df.movieId = df.movieId.astype(str)\n",
    "    \n",
    "    for period,period_df in df.groupby(pd.Grouper(freq = frequency)):\n",
    "        output = period_df.groupby(\"userId\").movieId.apply(lambda x: \" \".join(x)).to_frame().reset_index()\n",
    "        output.movieId = output.userId.astype(str)+\" \"+ output.movieId\n",
    "        output.drop([\"userId\"],inplace=True,axis=1)\n",
    "        output.to_csv(str(period),header=None,index=None)\n",
    "        yield period\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A399DBGVBzC5"
   },
   "source": [
    "### 2. Une fonction qui prend les arguments suivants:\n",
    "- un couple (partition, période de temps)\n",
    "- la valeur du support\n",
    "<br>Cette fonction fait appel à pmr.pylcm et retourne des groupes fréquents selon leur support\n",
    "Group description:[set of items] (support) Group content:[set of users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kP-bt7QkBzC5"
   },
   "outputs": [],
   "source": [
    "def format_output(results,period):\n",
    "    \"\"\"Format lcm output to:\n",
    "    Group description:[set of items] (support) Group content:[Sorted set of users] \n",
    "    \"\"\"\n",
    "    item_sets,supports,groups,periods = [],[],[],[]\n",
    "    for i,j in zip(results[3::2],results[4::2]):\n",
    "        if '(' not in i:\n",
    "            break\n",
    "        *items,support = re.findall(\"([0-9]+)+\",i)\n",
    "        items = ','.join(e for e in items)\n",
    "        group = j[1:]\n",
    "        item_sets.append(items)\n",
    "        supports.append(support)\n",
    "        periods.append(period)\n",
    "        groups.append(group)\n",
    "    return item_sets,supports,groups,periods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KecjnU7pBzC_"
   },
   "source": [
    "### 3. Une fonction qui prend en argument:\n",
    "Group description:[set of items] (support) Group content:[set of users]\n",
    "et qui retourne pour chaque user, l’ensemble des groupes auxquels il appartient sous la forme:\n",
    "(user_id, group_id, période de temps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKntwaKBzC_"
   },
   "outputs": [],
   "source": [
    "def users_groups(df,output=\"result.csv\"):\n",
    "    # split each user from the group to a new line : [[user_id,group,period],]\n",
    "    res = pd.DataFrame(df.users_ids.str.split(\",\").tolist(),index=[df.period,df.group]).stack()\n",
    "    res = res.reset_index([0,\"group\",\"period\"])\n",
    "    res.columns = [\"period\",\"group_id\",\"user_id\"]\n",
    "    res = res[['user_id','group_id','period']]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmQlmUtnBzDC"
   },
   "source": [
    "### Mining function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCC3vU43BzDD"
   },
   "outputs": [],
   "source": [
    "def run_lcm(input_file=None,support=None,itemsets_size=[5,100]):\n",
    "    \"\"\"Runs LCM (Single Thread)  and return the  result formated with format_output\n",
    "    \n",
    "    Example for parameters : input_file='1999',support=6, itemsets_size=[5,100]\n",
    "    Executed command :  $ ./lcm C_QI -l 5 -u 100 1999 6 -\n",
    "    \n",
    "    Preconfigured parameters:  \n",
    "     C: enumerate closed frequent itemsets\n",
    "     Q: output the frequency on the head of each itemset found,\n",
    "     I: output ID's of transactions including each itemset; ID of a transaction is given by the number of line in which the transaction is written. The ID starts from 0.\n",
    "     _: no output to standard output (including messages w.r.t. input data)\n",
    "     -l,-u [num]: enumerate itemsets with size at least/most [num]  \n",
    "   \n",
    "    Output:\n",
    "        Replace file having name input_file with the result : support,itemset,users\n",
    "        if no itemset found the input_file is deleted and output is empty string \"\"\n",
    "    \"\"\"\n",
    "    input_file= str(input_file)\n",
    "    \n",
    "    result = !./lcm C_QI -l {itemsets_size[0]} -u {itemsets_size[1]} {input_file} {support} -\n",
    "    if \"there is no frequent item\" in str(result) or result == []:\n",
    "        print(\"No itemset\",input_file)\n",
    "        try:\n",
    "            !rm {str(input_file)}\n",
    "        except:\n",
    "            pass\n",
    "        return ''\n",
    "    \n",
    "    # #transaction to user_id and replace input_file with result\n",
    "    reformat_output(input_file,result)\n",
    "    \n",
    "    return input_file\n",
    "\n",
    "\n",
    "\n",
    "def multithread_lcm(input_file,frequency,support,itemsets_size,dataset_filter):\n",
    "    f = partial(run_lcm,support=support,itemsets_size=itemsets_size)\n",
    "    p = Pool(8)\n",
    "    res  = p.map(f,split_dataset(input_file,frequency,dataset_filter))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return res\n",
    "\n",
    "def permut(x,data):\n",
    "    output= \"\"\n",
    "    for i in x.split(' '):\n",
    "        if i is \"\":\n",
    "            continue\n",
    "        output+= str(data[0][int(i)])+' '\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def form_group(x,permutations):\n",
    "    output = ''\n",
    "    for i in x.split(\" \"):\n",
    "        if i is not \"\":\n",
    "            output+=str(permutations[0][int(i)])+\",\"     \n",
    "    return output[:-1]\n",
    "\n",
    "def combine_outputs(files_names):\n",
    "    \"\"\"\n",
    "    Output : Dataframe,Dataframe\n",
    "        content of files in files_names in one dataframe\n",
    "        content of permutations files associated in one dataframe \n",
    "    \"\"\"\n",
    "    combined_csv = pd.DataFrame()\n",
    "    permutations = pd.DataFrame()\n",
    "\n",
    "    for i in files_names:\n",
    "        permut_file = \"permut\"+str(i)\n",
    "        try:# when l is too small even if lcm find results, file is created by empty\n",
    "            df = pd.read_csv(i,header=None)\n",
    "        except:\n",
    "            continue\n",
    "        df[\"period\"] = i \n",
    "        combined_csv= pd.concat([combined_csv,df])\n",
    "        df = pd.read_csv(permut_file ,header=None)\n",
    "        df[\"period\"] = i \n",
    "        permutations= pd.concat([permutations,df])\n",
    "    return combined_csv,permutations\n",
    "\n",
    "def reformat_output(input_file,unformated_result):\n",
    "    \"\"\"\n",
    "    Reformat default output of lcm : (support),itemset,#transations\n",
    "    to a file having name:  input_file and structure : support|itemsets|users\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    permutation = pd.read_csv(str(input_file),header=None)[0].apply(lambda x: x.split(\" \")[0])\n",
    "    for i,j in zip(unformated_result[0::2],unformated_result[1::2]):\n",
    "        support,*itemset = i.split()\n",
    "        itemset = j\n",
    "        support = support[1:-1]\n",
    "        users = \" \".join([str(permutation[int(z)]) for z in j.split()])\n",
    "        result.append(f'{support}|{itemset}|{users}')\n",
    "    \n",
    "    # Permut #transaction to user_id\n",
    "    pd.DataFrame(result).to_csv(input_file,header=None,index=None)\n",
    "    return result \n",
    "\n",
    "def encode_groups(df):\n",
    "    \"\"\"Label encoding from column users_ids in dataframe input\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[\"group\"]= le.fit_transform(df[\"users_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGCw1dVCBzDF"
   },
   "source": [
    "# Run the code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghmcjZZdBzDG"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubk_gZFeBzDH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def linear_closed_itemset_miner(input_file,frequency,support,itemsets_size,dataset_filter):\n",
    "    output = multithread_lcm(input_file,frequency,support,itemsets_size,dataset_filter)\n",
    "    res = [i for i in  output if i is not \"\"]\n",
    "    df = pd.DataFrame()\n",
    "    for i in res:\n",
    "        if i is \"\":\n",
    "            continue\n",
    "        df = pd.concat([df,pd.read_csv(i,sep=\"|\",header=None)],axis=0)\n",
    "    df.columns = [\"support\",\"itemsets\",\"users\"]\n",
    "    \n",
    "    output_file = f'{frequency}-{support}-[{itemsets_size[0]}-{itemsets_size[1]}]-{dataset_filter}-groups.dat'\n",
    "    df.to_csv(output_file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_closed_itemset_miner(\"ratings.csv\",\"Y\",50,[2,15],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filter = \"\"\n",
    "for frequency in [\"Y\",\"6M\",\"3M\",\"2M\",\"M\"]:\n",
    "    for support in [20,30,50,100,200,1000 ]:\n",
    "        for itemsets_size in [[2,5],[2,10],[2,20],[20,50],[2,100]]:\n",
    "            output_file = f'{frequency}-{support}-[{itemsets_size[0]}-{itemsets_size[1]}]-groups.dat'\n",
    "            try:\n",
    "                df = linear_closed_itemset_miner(input_file,frequency,support,itemsets_size,output_file,dataset_filter)\n",
    "                print(output_file)\n",
    "                ICD.display(df.group.value_counts().to_frame().head())\n",
    "            except Exception as e:\n",
    "                print(\"Exception For : \",output_file)\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Version Groups of users having same demographic properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Groupby using ranges ex: age within ranges of size 10 \n",
    "def dataset_property_split(df,frequency,properties):\n",
    "    for period,i in df.groupby(pd.Grouper(freq = frequency)):\n",
    "        for values,ii in i.groupby(properties):\n",
    "            if len(properties)>1:\n",
    "                values = '_'.join(str(z) for z in values)\n",
    "            split_name = f\"{period}_{values}\"\n",
    "            ii = ii.groupby('user_id')[\"movie_id\"].apply(\n",
    "                    lambda x: \" \".join(str(z) for z in x)\n",
    "            )\n",
    "            ii.reindex(np.arange(ii.index.max())).fillna(',').to_csv(\n",
    "                split_name,index=False,header=False,sep = '\\t', quoting = csv.QUOTE_NONE, escapechar = ' '\n",
    "            )        \n",
    "            yield str(split_name)\n",
    "        \n",
    "def reformat_output(unformated_result):\n",
    "    \"\"\"\n",
    "    Reformat default output of lcm  to a dataframe with structure : support,itemsets,users\n",
    "    \"\"\"\n",
    "    output = pd.DataFrame([unformated_result[0::2],unformated_result[1::2]]).T\n",
    "    output = pd.concat([output.drop(0,axis=1),output[0].str.split('\\(([0-9]+)\\)',expand=True).drop(0,axis=1)],axis=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def run_lcm(split_name,support,itemsets_size,output_file):\n",
    "    \"\"\"Runs LCM (Single Thread)  and return the  result formated with format_output\n",
    "    \n",
    "    Example for parameters : input_file='1999',support=6, itemsets_size=[5,100]\n",
    "    Executed command :  $ ./lcm C_QI -l 5 -u 100 1999 6 -\n",
    "    \n",
    "    Preconfigured parameters:  \n",
    "     C: enumerate closed frequent itemsets\n",
    "     Q: output the frequency on the head of each itemset found,\n",
    "     I: output ID's of transactions including each itemset; ID of a transaction is given by the number of line in which the transaction is written. The ID starts from 0.\n",
    "     _: no output to standard output (including messages w.r.t. input data)\n",
    "     -l,-u [num]: enumerate itemsets with size at least/most [num]  \n",
    "   \n",
    "    Output:\n",
    "        Replace file having name input_file with the result : support,itemset,users\n",
    "        if no itemset found the input_file is deleted and output is empty string \"\"\n",
    "    \"\"\"\n",
    "    result = !./lcm C_QI -l {itemsets_size[0]} -u {itemsets_size[1]} {split_name} {support} -\n",
    "    if \"there is no frequent item\" in str(result) or result == []:\n",
    "        print(\"No itemset\",split_name)\n",
    "        return \n",
    "    print(\"Found \",len(result)/2,\" in\",split_name )\n",
    "    reformat_output(result).to_csv(output_file,header=False,index=None,mode=\"a\")\n",
    "    return split_name\n",
    "\n",
    "\n",
    "def multithread_lcm(input_file,frequency,support,itemsets_size,properties,output_file):\n",
    "    f = partial(run_lcm,support=support,itemsets_size=itemsets_size,output_file=output_file)\n",
    "    p = Pool(8)\n",
    "    res  = p.imap_unordered(f,dataset_property_split(input_file,frequency,properties))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return res\n",
    "                                              \n",
    "def linear_closed_itemset_miner(df,frequency,support,itemsets_size,properties):\n",
    "    output_file = f'{frequency}-{support}-[{itemsets_size[0]}-{itemsets_size[1]}]-[{\"_\".join(str(i) for i in properties)}]-groups.dat'\n",
    "    try:\n",
    "        !rm {output_file}\n",
    "    except:\n",
    "        pass\n",
    "    a = multithread_lcm(df,frequency,support,itemsets_size,properties,output_file)\n",
    "    a = [i for i in a if i is not None]\n",
    "\n",
    "def age_class(age):\n",
    "    age = np.int(age)\n",
    "    if age<=12:\n",
    "        return 0\n",
    "    if age<=17:\n",
    "        return 1\n",
    "    if age<=24:\n",
    "        return 2\n",
    "    if age<=34:\n",
    "        return 3\n",
    "    if age<=44:\n",
    "        return 4\n",
    "    if age<44:\n",
    "        return 5\n",
    "    if age<=54:\n",
    "        return 6\n",
    "    if age<=74:\n",
    "        return 7\n",
    "    return 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting dataset ready\n",
    "1. Merge users and ratigns dataset \n",
    "2. split ages into small ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_occupation</th>\n",
       "      <th>user_zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-31 22:12</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-31 22:35</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-31 22:32</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-31 22:04</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-06 23:38</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  movie_id  rating user_gender  user_age  \\\n",
       "timestamp                                                           \n",
       "2000-12-31 22:12        1      1193       5           F         0   \n",
       "2000-12-31 22:35        1       661       3           F         0   \n",
       "2000-12-31 22:32        1       914       3           F         0   \n",
       "2000-12-31 22:04        1      3408       4           F         0   \n",
       "2001-01-06 23:38        1      2355       5           F         0   \n",
       "\n",
       "                  user_occupation user_zip_code  \n",
       "timestamp                                        \n",
       "2000-12-31 22:12               10         48067  \n",
       "2000-12-31 22:35               10         48067  \n",
       "2000-12-31 22:32               10         48067  \n",
       "2000-12-31 22:04               10         48067  \n",
       "2001-01-06 23:38               10         48067  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratings dataframe \n",
    "df = pd.read_csv(\"datasets/ml-1m/ml-1m/ratings.dat\",sep='::',header=None,engine='python')\n",
    "df.columns = [\"user_id\",\"movie_id\",\"rating\",\"timestamp\"]\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],unit=\"s\").dt.to_period(\"T\")\n",
    "\n",
    "# Users dataframe \n",
    "users = pd.read_csv(\"datasets/ml-1m/ml-1m/users.dat\",header=None,sep=\"::\",engine=\"python\")\n",
    "users.columns = [\"user_id\",\"user_gender\",\"user_age\",\"user_occupation\",\"user_zip_code\"]\n",
    "users.set_index(\"user_id\").head()\n",
    "# User age to ranges \n",
    "users.user_age = users.user_age.apply(lambda x : age_class(x))\n",
    "# merge both\n",
    "df = df.merge(users,on=\"user_id\")\n",
    "df.set_index([\"timestamp\"],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: impossible de supprimer '7D-20-[2-5]-[user_gender]-groups.dat': Aucun fichier ou dossier de ce type\n",
      "No itemset 2000-04-25_F\n",
      "Found  68.0  in 2000-04-25_M\n",
      "No itemset 2000-05-02_F\n",
      "Found  35.0  in 2000-05-02_M\n",
      "No itemset 2000-05-09_F\n",
      "Found  411.0  in 2000-05-09_M\n",
      "Found  271.0  in 2000-05-16_M\n",
      "No itemset 2000-05-23_F\n",
      "Found  304.0  in 2000-05-23_M\n",
      "No itemset 2000-05-30_F\n",
      "No itemset 2000-05-16_F\n",
      "Found  758.0  in 2000-05-30_M\n",
      "No itemset 2000-06-06_F\n",
      "Found  5.0  in 2000-06-06_M\n",
      "Found  4.0  in 2000-06-13_M\n",
      "Found  21.0  in 2000-06-20_M\n",
      "No itemset 2000-06-27_F\n",
      "No itemset 2000-06-13_F\n",
      "No itemset 2000-06-20_F\n",
      "Found  1.0  in 2000-07-04_F\n",
      "Found  15.0  in 2000-07-11_M\n",
      "Found  3183.0  in 2000-07-04_M\n",
      "Found  1.0  in 2000-07-18_M\n",
      "No itemset 2000-07-11_F\n",
      "Found  345.0  in 2000-07-25_M\n",
      "No itemset 2000-07-18_F\n",
      "Found  94.0  in 2000-08-01_F\n",
      "No itemset 2000-07-25_F\n",
      "Found  2.0  in 2000-08-08_F\n",
      "No itemset 2000-08-22_F\n",
      "No itemset 2000-08-15_F\n",
      "Found  19007.0  in 2000-06-27_M\n",
      "Found  105.0  in 2000-08-29_M\n",
      "No itemset 2000-09-05_F\n",
      "No itemset 2000-08-29_F\n",
      "Found  83.0  in 2000-09-05_M\n",
      "Found  1.0  in 2000-09-12_M\n",
      "Found  8190.0  in 2000-08-22_M\n",
      "No itemset 2000-09-12_F\n",
      "No itemset 2000-09-19_M\n",
      "No itemset 2000-09-19_F\n",
      "Found  12425.0  in 2000-08-15_M\n",
      "Found  3.0  in 2000-09-26_M\n",
      "No itemset 2000-09-26_F\n",
      "Found  1.0  in 2000-10-03_M\n",
      "No itemset 2000-10-03_F\n",
      "No itemset 2000-10-10_F\n",
      "No itemset 2000-10-10_M\n",
      "No itemset 2000-10-17_F\n",
      "No itemset 2000-10-17_M\n",
      "No itemset 2000-10-31_F\n",
      "Found  39.0  in 2000-10-24_M\n",
      "No itemset 2000-11-07_F\n",
      "Found  191.0  in 2000-10-31_M\n",
      "No itemset 2000-10-24_F\n",
      "Found  2213.0  in 2000-11-07_M\n",
      "Found  5636.0  in 2000-11-14_F\n",
      "Found  2395.0  in 2000-11-21_F\n",
      "Found  4.0  in 2000-11-28_F\n",
      "Found  6.0  in 2000-12-05_F\n",
      "Found  663.0  in 2000-12-12_M\n",
      "No itemset 2000-12-12_F\n",
      "Found  55.0  in 2000-12-19_M\n",
      "No itemset 2000-12-19_F\n",
      "Found  14.0  in 2000-12-26_M\n",
      "No itemset 2000-12-26_F\n",
      "No itemset 2001-01-02_F\n",
      "No itemset 2001-01-02_M\n",
      "No itemset 2001-01-09_F\n",
      "No itemset 2001-01-09_M\n",
      "No itemset 2001-01-16_F\n",
      "No itemset 2001-01-16_M\n",
      "No itemset 2001-01-23_F\n",
      "No itemset 2001-01-23_M\n",
      "No itemset 2001-01-30_F\n",
      "No itemset 2001-01-30_M\n",
      "No itemset 2001-02-06_F\n",
      "No itemset 2001-02-06_M\n",
      "No itemset 2001-02-13_F\n",
      "No itemset 2001-02-13_M\n",
      "No itemset 2001-02-20_F\n",
      "No itemset 2001-02-20_M\n",
      "No itemset 2001-02-27_F\n",
      "No itemset 2001-02-27_M\n",
      "No itemset 2001-03-06_F\n",
      "No itemset 2001-03-06_M\n",
      "No itemset 2001-03-13_F\n",
      "No itemset 2001-03-13_M\n",
      "No itemset 2001-03-20_F\n",
      "No itemset 2001-03-20_M\n",
      "No itemset 2001-03-27_F\n",
      "No itemset 2001-03-27_M\n",
      "No itemset 2001-04-03_F\n",
      "No itemset 2001-04-03_M\n",
      "No itemset 2001-04-10_F\n",
      "No itemset 2001-04-10_M\n",
      "No itemset 2001-04-17_F\n",
      "No itemset 2001-04-17_M\n",
      "No itemset 2001-04-24_F\n",
      "No itemset 2001-04-24_M\n",
      "No itemset 2001-05-01_F\n",
      "No itemset 2001-05-01_M\n",
      "No itemset 2001-05-08_F\n",
      "No itemset 2001-05-08_M\n",
      "No itemset 2001-05-15_F\n",
      "No itemset 2001-05-15_M\n",
      "No itemset 2001-05-22_F\n",
      "No itemset 2001-05-22_M\n",
      "No itemset 2001-05-29_F\n",
      "No itemset 2001-05-29_M\n",
      "No itemset 2001-06-05_F\n",
      "No itemset 2001-06-05_M\n",
      "No itemset 2001-06-12_F\n",
      "No itemset 2001-06-12_M\n",
      "No itemset 2001-06-19_F\n",
      "No itemset 2001-06-19_M\n",
      "No itemset 2001-06-26_F\n",
      "No itemset 2001-06-26_M\n",
      "No itemset 2001-07-03_F\n",
      "No itemset 2001-07-03_M\n",
      "No itemset 2001-07-10_F\n",
      "No itemset 2001-07-10_M\n",
      "No itemset 2001-07-17_F\n",
      "No itemset 2001-07-17_M\n",
      "No itemset 2001-07-24_F\n",
      "No itemset 2001-07-24_M\n",
      "No itemset 2001-07-31_F\n",
      "No itemset 2001-07-31_M\n",
      "No itemset 2001-08-07_F\n",
      "No itemset 2001-08-07_M\n",
      "No itemset 2001-08-14_F\n",
      "No itemset 2001-08-14_M\n",
      "No itemset 2001-08-21_F\n",
      "No itemset 2001-08-21_M\n",
      "No itemset 2001-08-28_F\n",
      "No itemset 2001-08-28_M\n",
      "No itemset 2001-09-04_F\n",
      "No itemset 2001-09-04_M\n",
      "No itemset 2001-09-11_F\n",
      "No itemset 2001-09-11_M\n",
      "No itemset 2001-09-18_F\n",
      "No itemset 2001-09-18_M\n",
      "No itemset 2001-09-25_M\n",
      "No itemset 2001-09-25_F\n",
      "No itemset 2001-10-02_F\n",
      "No itemset 2001-10-02_M\n",
      "No itemset 2001-10-09_F\n",
      "No itemset 2001-10-09_M\n",
      "No itemset 2001-10-16_F\n",
      "No itemset 2001-10-16_M\n",
      "No itemset 2001-10-23_F\n",
      "No itemset 2001-10-23_M\n",
      "No itemset 2001-10-30_F\n",
      "No itemset 2001-10-30_M\n",
      "No itemset 2001-11-06_F\n",
      "No itemset 2001-11-06_M\n",
      "No itemset 2001-11-13_F\n",
      "No itemset 2001-11-13_M\n",
      "No itemset 2001-11-20_F\n",
      "No itemset 2001-11-20_M\n",
      "No itemset 2001-11-27_F\n",
      "No itemset 2001-11-27_M\n",
      "No itemset 2001-12-04_F\n",
      "No itemset 2001-12-04_M\n",
      "No itemset 2001-12-11_F\n",
      "No itemset 2001-12-11_M\n",
      "No itemset 2001-12-18_F\n",
      "No itemset 2001-12-18_M\n",
      "No itemset 2001-12-25_F\n",
      "No itemset 2001-12-25_M\n",
      "No itemset 2002-01-01_F\n",
      "No itemset 2002-01-01_M\n",
      "No itemset 2002-01-08_F\n",
      "No itemset 2002-01-08_M\n",
      "No itemset 2002-01-15_F\n",
      "No itemset 2002-01-15_M\n",
      "No itemset 2002-01-22_F\n",
      "No itemset 2002-01-22_M\n",
      "No itemset 2002-01-29_F\n",
      "No itemset 2002-01-29_M\n",
      "No itemset 2002-02-05_F\n",
      "No itemset 2002-02-05_M\n",
      "No itemset 2002-02-12_F\n",
      "No itemset 2002-02-12_M\n",
      "No itemset 2002-02-19_F\n",
      "No itemset 2002-02-19_M\n",
      "No itemset 2002-02-26_F\n",
      "No itemset 2002-02-26_M\n",
      "No itemset 2002-03-05_F\n",
      "No itemset 2002-03-05_M\n",
      "No itemset 2002-03-12_F\n",
      "No itemset 2002-03-19_F\n",
      "No itemset 2002-03-12_M\n",
      "No itemset 2002-03-19_M\n",
      "No itemset 2002-03-26_F\n",
      "No itemset 2002-03-26_M\n",
      "No itemset 2002-04-02_F\n",
      "No itemset 2002-04-02_M\n",
      "No itemset 2002-04-09_F\n",
      "No itemset 2002-04-16_F\n",
      "No itemset 2002-04-09_M\n",
      "No itemset 2002-04-16_M\n",
      "No itemset 2002-04-23_F\n",
      "No itemset 2002-04-23_M\n",
      "No itemset 2002-04-30_F\n",
      "No itemset 2002-04-30_M\n",
      "No itemset 2002-05-07_F\n",
      "No itemset 2002-05-07_M\n",
      "No itemset 2002-05-14_F\n",
      "No itemset 2002-05-14_M\n",
      "No itemset 2002-05-21_F\n",
      "No itemset 2002-05-21_M\n",
      "No itemset 2002-05-28_F\n",
      "No itemset 2002-05-28_M\n",
      "No itemset 2002-06-04_F\n",
      "No itemset 2002-06-04_M\n",
      "No itemset 2002-06-11_F\n",
      "No itemset 2002-06-11_M\n",
      "No itemset 2002-06-18_F\n",
      "No itemset 2002-06-18_M\n",
      "No itemset 2002-06-25_F\n",
      "No itemset 2002-06-25_M\n",
      "Found  141623.0  in 2000-12-05_M\n",
      "No itemset 2002-07-02_F\n",
      "No itemset 2002-07-02_M\n",
      "No itemset 2002-07-09_F\n",
      "No itemset 2002-07-09_M\n",
      "No itemset 2002-07-16_F\n",
      "No itemset 2002-07-16_M\n",
      "No itemset 2002-07-23_F\n",
      "No itemset 2002-07-23_M\n",
      "No itemset 2002-07-30_F\n",
      "No itemset 2002-07-30_M\n",
      "No itemset 2002-08-06_F\n",
      "No itemset 2002-08-06_M\n",
      "No itemset 2002-08-13_F\n",
      "No itemset 2002-08-13_M\n",
      "No itemset 2002-08-20_F\n",
      "No itemset 2002-08-20_M\n",
      "No itemset 2002-08-27_F\n",
      "No itemset 2002-08-27_M\n",
      "No itemset 2002-09-03_F\n",
      "No itemset 2002-09-03_M\n",
      "No itemset 2002-09-10_F\n",
      "No itemset 2002-09-10_M\n",
      "No itemset 2002-09-17_F\n",
      "No itemset 2002-09-17_M\n",
      "No itemset 2002-09-24_F\n",
      "Found  189387.0  in 2000-11-28_M\n",
      "No itemset 2002-09-24_M\n",
      "No itemset 2002-10-01_F\n",
      "No itemset 2002-10-08_F\n",
      "No itemset 2002-10-01_M\n",
      "No itemset 2002-10-08_M\n",
      "No itemset 2002-10-15_F\n",
      "No itemset 2002-10-15_M\n",
      "No itemset 2002-10-22_F\n",
      "No itemset 2002-10-22_M\n",
      "No itemset 2002-10-29_F\n",
      "No itemset 2002-10-29_M\n",
      "No itemset 2002-11-05_F\n",
      "No itemset 2002-11-05_M\n",
      "No itemset 2002-11-12_F\n",
      "No itemset 2002-11-12_M\n",
      "No itemset 2002-11-19_F\n",
      "No itemset 2002-11-19_M\n",
      "No itemset 2002-11-26_F\n",
      "No itemset 2002-11-26_M\n",
      "No itemset 2002-12-03_F\n",
      "No itemset 2002-12-03_M\n",
      "Found  189335.0  in 2000-08-08_M\n",
      "No itemset 2002-12-10_F\n",
      "No itemset 2002-12-10_M\n",
      "No itemset 2002-12-17_F\n",
      "No itemset 2002-12-17_M\n",
      "No itemset 2002-12-24_F\n",
      "No itemset 2002-12-24_M\n",
      "No itemset 2002-12-31_F\n",
      "No itemset 2002-12-31_M\n",
      "No itemset 2003-01-07_F\n",
      "No itemset 2003-01-07_M\n",
      "No itemset 2003-01-14_F\n",
      "No itemset 2003-01-14_M\n",
      "No itemset 2003-01-21_F\n",
      "No itemset 2003-01-21_M\n",
      "No itemset 2003-01-28_F\n",
      "No itemset 2003-01-28_M\n",
      "No itemset 2003-02-04_F\n",
      "No itemset 2003-02-04_M\n",
      "No itemset 2003-02-11_F\n",
      "No itemset 2003-02-11_M\n",
      "No itemset 2003-02-18_F\n",
      "No itemset 2003-02-18_M\n",
      "No itemset 2003-02-25_F\n",
      "No itemset 2003-02-25_M\n"
     ]
    }
   ],
   "source": [
    "input_file=\"ratings.csv\"\n",
    "frequencies =[\"7D\",\"21D\",\"M\",\"2M\",\"3M\",\"Y\"]\n",
    "supports = [20,25,30,35,50,75,100,200,1000]\n",
    "itemsets_sizes =  [[2,5],[2,10],[2,20],[10,20],[15,20],[2,100]]\n",
    "properties = [[\"user_gender\"],[\"user_age\"],[\"user_zip_code\"],[\"user_age\",\"user_gender\"],[\"user_gender\",\"user_occupation\"],[\"user_zip_code\",\"user_age\"],[\"user_zip_code\",\"user_age\",\"user_gender\"]]\n",
    "for i in itertools.product(frequencies,supports,itemsets_sizes,properties):\n",
    "    linear_closed_itemset_miner(df,*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b0c2cd796a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msplit_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{period}_{values}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         ii = ii.groupby('user_id')[\"movie_id\"].apply(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LCM Minner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
