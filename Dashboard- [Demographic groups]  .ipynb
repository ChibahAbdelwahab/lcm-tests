{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core import display as ICD\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer\n",
    "from itertools import groupby, product\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcm_output(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z) for z in x.split(\" \") if z != \"\"]))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm_results_overview(folder_name):\n",
    "    files = !ls {folder_name}/\n",
    "    res = []\n",
    "    for i in files:\n",
    "        a= pd.read_csv(folder_name+\"/\"+i,sep=\",\",header=None)\n",
    "        a.columns = [\"itemsets\",\"support\",\"user_ids\",\"period\",\"property_values\"]\n",
    "        a[\"period\"]=a[\"period\"].apply(lambda x:x.split(\"_\")[0])\n",
    "        mean = a[\"property_values\"].value_counts().mean()\n",
    "        unique = a[\"property_values\"].nunique()\n",
    "        indice = a[[\"period\",\"property_values\"]].drop_duplicates().period.value_counts().mean()/a.property_values.nunique()\n",
    "        res.append((i,mean,unique,a.shape,indice))\n",
    "    df = pd.DataFrame(res)\n",
    "    df.columns = [\"filename\",\"mean property_values occurence\",\"unique property values\",\"file shape\",\"indice\"]\n",
    "    return df \n",
    "def format_name(name):\n",
    "    return name.split(\"/\")[1].split(\"-\")\n",
    "\n",
    "def jaccard_similarity(a, b):\n",
    "    \"\"\"Compute Jaccard distance between two arrays\n",
    "    Inputs :\n",
    "        a: n element array\n",
    "        b: m element array\n",
    "    \"\"\"\n",
    "    return len(a[0].intersection(b[0]))/len(a[0].union(b[0]))\n",
    "\n",
    "\n",
    "def similar_groups_union(groups,g_index,threashold):\n",
    "    \"\"\"\n",
    "    Create new groups from given ones,\n",
    "    each group is affected to the new group having the minimal jaccard distance with (comparing to all new groups)\n",
    "    if the minimal jaccard distance found is under the threashold, the group is added as a new group \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : list of tuples of strhttp://localhohttp://localhost:8888/notebooks/%5BDemographic%20Groups%5D%20EDA.ipynbst:8888/notebooks/%5BDemographic%20Groups%5D%20EDA.ipynb\n",
    "        Each tuple contain user_ids \n",
    "    g_index: list of int\n",
    "        list of corresponding indexes in initial dataset\n",
    "    Returns\n",
    "    -------\n",
    "    list of new groups and their corresponding indexes in the given dataset\n",
    "    \"\"\"\n",
    "    new_groups = [[groups[0],[g_index[0]]],]\n",
    "    for group,g_idx in zip(groups[1:],g_index[1:]):\n",
    "        group = set(group)\n",
    "        found = False\n",
    "        for i in new_groups:\n",
    "            distance = 1-len(group.intersection(i[0]))/len(group.union(i[0]))\n",
    "            if distance<threashold:\n",
    "                group_n = tuple(group.union(i[0]))\n",
    "                for z in new_groups:\n",
    "                    if z[0]== group_n:\n",
    "                        z[1].append(g_idx)\n",
    "                        new_groups.remove(i)\n",
    "                        break\n",
    "                i[0] = tuple(group.union(i[0]))\n",
    "                i[1].append(g_idx)\n",
    "                found = True\n",
    "        if not found:\n",
    "            new_groups.append([tuple(group),[g_idx]])\n",
    "    return new_groups\n",
    "\n",
    "def recompute_groups(df,properties,threashold):\n",
    "    \"\"\"\n",
    "    Regroup similar groups of each period to new groups according to the Jaccard distance between them\n",
    "    Parameters\n",
    "    ----------\n",
    "        df: DataFrame \n",
    "        threashold: int  \n",
    "            Minimal Jaccard distance under which two groups are supposed similar\n",
    "    Result\n",
    "    ------\n",
    "        Dataframe \n",
    "    \"\"\"\n",
    "    groups = pd.DataFrame()\n",
    "    for (period,values),i in df.groupby(properties):\n",
    "        g =  [tuple(str(z) for z in x) for x in i.user_ids]\n",
    "        res = pd.DataFrame(similar_groups_union(g,i.index,threashold))\n",
    "        res[\"properties\"] = values\n",
    "        res[\"period\"] = period\n",
    "        groups = pd.concat([groups,res],axis=0,sort=False)\n",
    "    groups.columns = [\"user_ids\",\"groups_ids\",\"property_values\",\"period\"]\n",
    "    return groups.reset_index(drop=\"True\")\n",
    "\n",
    "\n",
    "def compute_distance(x):\n",
    "    return 1-len(x[\"user_ids_x\"].intersection(x[\"user_ids_y\"]))/len(x[\"user_ids_x\"].union(x[\"user_ids_x\"]))\n",
    "\n",
    "\n",
    "def compute_groups_interactions(df_reduced,input_name,interaction_folder=\"groups_interactions\",groups_folder=\"groups\"):\n",
    "    \"\"\"Create jaccard pairwise distances table for groups having same property_values over two concecutive periods\"\"\"\n",
    "    # remove file if already existing\n",
    "    file = f\"{interaction_folder}/{input_name}\"\n",
    "    os.path.exists(file) and os.remove(file)\n",
    "    lb = MultiLabelBinarizer()\n",
    "    users = lb.fit_transform(df_reduced.user_ids.tolist()).astype(bool)\n",
    "    \n",
    "    for (period,property_values),i in df_reduced.groupby([\"period\",\"property_values\"]):\n",
    "        comp_idx = df_reduced[(df_reduced.period>period )&(df_reduced.period-period < timedelta(60))&(df_reduced.property_values==property_values)].index\n",
    "        if comp_idx.shape==(0,):\n",
    "            continue\n",
    "        res = pd.DataFrame(pairwise_distances(users[i.index],users[comp_idx],metric=\"jaccard\",n_jobs=-1),index=i.index,columns=comp_idx) \n",
    "        res = res[res<1].stack().reset_index()\n",
    "        res.to_csv(file,header=False,index=False,mode=\"a\")\n",
    "    \n",
    "    groups_df = pd.read_csv(file,header=None)\n",
    "\n",
    "    \n",
    "    df_trans = groups_df.merge(df_reduced,left_on=0,right_on=\"index\").merge(df_reduced,left_on=1,right_on=\"index\")\n",
    "    df_trans.drop([0,1,2],axis=1,inplace=True)\n",
    "    df_trans[\"changes\"] = df_trans[[\"user_ids_x\",\"user_ids_y\"]].apply(lambda x : set(x[\"user_ids_x\"]).intersection(x[\"user_ids_y\"]),axis=1)\n",
    "    df_trans[\"#changes\"] = df_trans[\"changes\"].apply(lambda x: len(x))\n",
    "    \n",
    "   \n",
    "    df_trans.to_csv(file,header=True,index=False)\n",
    "    \n",
    "#     file = f\"{groups_folder}/{input_name}\"\n",
    "#     os.path.exists(file) and os.remove(file)\n",
    "#     df_reduced.to_csv(file,header=True,index=False)\n",
    "    \n",
    "    return df_trans\n",
    "\n",
    "def read_reduced_groups(filename,folder=\"reduced_groups\"):\n",
    "    file = f'{folder}/{filename}'\n",
    "    df = pd.read_csv(file,index_col=0)\n",
    "    df[\"user_ids\"] = df[\"user_ids\"].apply(lambda x: [int(z.replace(\"'\",\"\")) for z in x[1:-1].split(\",\")])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(i):\n",
    "    if i<=5:\n",
    "        return '#fecb00'\n",
    "    if i<=10:\n",
    "        return '#d47600'\n",
    "    if i<=20: \n",
    "        return '#bb133e'\n",
    "    if i<=35:\n",
    "        return '#002664'\n",
    "    return '#000000'\n",
    "\n",
    "\n",
    "def genSankey(df,cat_cols=[],value_cols='',title='Sankey Diagram',df_reduced=[]):\n",
    "    colorPalette = []\n",
    "    color_size = 4\n",
    "    \n",
    "    labelList = []\n",
    "    colorNumList = []\n",
    "    for catCol in cat_cols:\n",
    "        labelListTemp =  list(set(df[catCol].values))\n",
    "        colorNumList.append(len(labelListTemp))\n",
    "        labelList = labelList + labelListTemp\n",
    "    labelList = [i for i in labelList if not np.isnan(i)]\n",
    "    # remove duplicates from labelList\n",
    "    labelList = list(dict.fromkeys(labelList))\n",
    "            \n",
    "    # transform df into a source-target pair\n",
    "    for i in range(len(cat_cols)-1):\n",
    "        if i==0:\n",
    "            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            sourceTargetDf.columns = ['source','target','count']\n",
    "        else:\n",
    "            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            tempDf.columns = ['source','target','count']\n",
    "            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "        sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n",
    "   \n",
    "    position_x,position_y,colorList = [],[],[]\n",
    "    for i in labelList:\n",
    "        i = int(i)\n",
    "        colorList.append(get_color(int(len(df_reduced.iloc[i].user_ids))))\n",
    "        position_x.append(df_reduced.iloc[i].position_x)\n",
    "        position_y.append(df_reduced.iloc[i].position_y)\n",
    "    # add index for source-target pair\n",
    "    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n",
    "    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n",
    "    # creating the sankey diagram\n",
    "    data = dict(\n",
    "        arrangement = \"snap\",\n",
    "        type='sankey',\n",
    "        node = dict(\n",
    "          pad = 1,\n",
    "          thickness = 20,\n",
    "          line = dict(\n",
    "            color = \"black\",\n",
    "            width = 0.5\n",
    "          ),\n",
    "          label = [f'size={len(df_reduced.iloc[int(i)].user_ids)}-{df_reduced.iloc[int(i)].period}' for i in labelList],\n",
    "          x = position_x,\n",
    "          y=position_y,\n",
    "          color = colorList\n",
    "        ),\n",
    "        link = dict(\n",
    "          source = sourceTargetDf['sourceID'],\n",
    "          target = sourceTargetDf['targetID'],\n",
    "          value = sourceTargetDf['count']\n",
    "        )\n",
    "      )\n",
    "    \n",
    "    layout =  dict(\n",
    "        title = title,\n",
    "        font = dict(\n",
    "          size = 10\n",
    "        )\n",
    "    )\n",
    "       \n",
    "    fig = dict(data=[data], layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of all results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mean property_values occurence</th>\n",
       "      <th>unique property values</th>\n",
       "      <th>file shape</th>\n",
       "      <th>indice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2M-5-[2-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>(239, 5)</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3M-5-[2-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>103.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>(310, 5)</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M-10-[2-5000]-[AGE]-lcm.out</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>(7274, 5)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M-10-[2-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M-10-[2-5000]-[SEX]-lcm.out</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>(29098, 5)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M-2-[1-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>52.769231</td>\n",
       "      <td>13</td>\n",
       "      <td>(686, 5)</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M-2-[2-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>(244, 5)</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M-5-[2-5000]-[AGE,SEX]-lcm.out</td>\n",
       "      <td>12942.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>(51769, 5)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M-5-[2-5000]-[DEPARTEMENT]-lcm.out</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>(145, 5)</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M-5-[2-5000]-[SEX]-lcm.out</td>\n",
       "      <td>50606.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>(101212, 5)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  mean property_values occurence  \\\n",
       "0  2M-5-[2-5000]-[DEPARTEMENT]-lcm.out                       79.666667   \n",
       "1  3M-5-[2-5000]-[DEPARTEMENT]-lcm.out                      103.333333   \n",
       "2          M-10-[2-5000]-[AGE]-lcm.out                     3637.000000   \n",
       "3  M-10-[2-5000]-[DEPARTEMENT]-lcm.out                        3.000000   \n",
       "4          M-10-[2-5000]-[SEX]-lcm.out                    14549.000000   \n",
       "5   M-2-[1-5000]-[DEPARTEMENT]-lcm.out                       52.769231   \n",
       "6   M-2-[2-5000]-[DEPARTEMENT]-lcm.out                       48.800000   \n",
       "7       M-5-[2-5000]-[AGE,SEX]-lcm.out                    12942.250000   \n",
       "8   M-5-[2-5000]-[DEPARTEMENT]-lcm.out                       48.333333   \n",
       "9           M-5-[2-5000]-[SEX]-lcm.out                    50606.000000   \n",
       "\n",
       "   unique property values   file shape    indice  \n",
       "0                       3     (239, 5)  0.784314  \n",
       "1                       3     (310, 5)  0.878788  \n",
       "2                       2    (7274, 5)  1.000000  \n",
       "3                       1       (3, 5)  1.000000  \n",
       "4                       2   (29098, 5)  1.000000  \n",
       "5                      13     (686, 5)  0.897436  \n",
       "6                       5     (244, 5)  0.733333  \n",
       "7                       4   (51769, 5)  1.000000  \n",
       "8                       3     (145, 5)  0.656250  \n",
       "9                       2  (101212, 5)  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcm_results_overview(\"lcm_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot sankeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reduced_groups/7D-5-[5-50000]-[user_age]-lcm.out']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = !ls reduced_groups/7*\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for i in ['reduced_groups/7D-5-[5-50000]-[user_age]-lcm.out']:\n",
    "#     df = read_lcm_output(i)\n",
    "#     df_reduced = recompute_groups(df,[\"period\",\"property_values\"],0.4) \n",
    "#     df_reduced.to_csv(f\"reduced_groups/{i}\")\n",
    "    df_reduced = read_reduced_groups(i,folder=\"\")\n",
    "    users = mlb.fit_transform(df_reduced.user_ids.tolist()).astype(bool).T\n",
    "    _df  = pd.DataFrame([np.where(user) for user in users if user.sum()>1])\n",
    "    e = _df[0].apply(lambda x: tuple(list(z) for idx,z in groupby(x,lambda y: df_reduced.iloc[y].period)))\n",
    "    e = e[e.apply(lambda x:len(x))>2]\n",
    "    print(\"done\")\n",
    "    if e.shape[0]==0:\n",
    "        print(\"Empty\")\n",
    "        continue\n",
    "    a = e.apply(lambda x : list(product(*x)))\n",
    "    b = pd.DataFrame(a.sum()) \n",
    "    c = b.fillna(\" \").groupby(b.columns.to_list()).size().reset_index(name='size')\n",
    "    c = c.replace(\" \",np.nan)\n",
    "    c[\"property_values\"] = c[0].apply(lambda x : df_reduced.iloc[x].property_values)\n",
    "    df_reduced[\"position_x\"] = le.fit_transform(df_reduced[\"period\"])/df_reduced[\"period\"].nunique()\n",
    "    df_reduced[\"position_y\"] = 1\n",
    "    for period, x in df_reduced.groupby(\"period\"):\n",
    "        res = x.reset_index().index/x.shape[0]\n",
    "        df_reduced[\"position_y\"].loc[x.index] =  res - min(res)\n",
    "    for e,ii in c.groupby(\"property_values\"):\n",
    "        fig = genSankey(ii,cat_cols=ii.columns.tolist()[:-2],value_cols='size',title=f\"{i},{e}\",df_reduced=df_reduced)\n",
    "        plotly.offline.plot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read lcm output \n",
    "2. Recompute groups \n",
    "3. Create transaction from groups\n",
    "4. store to /groups/ and /groups_interactions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_interactions(input_name,jaccard_threshold=0.5,output_folder=\"\",plot=True):\n",
    "    \"\"\"Recompute groups interaction for LCM output and store result in output_folder\"\"\"\n",
    "    \n",
    "    file = f'{output_folder}/{input_name}'\n",
    "    \n",
    "    df = read_lcm_output(input_name)\n",
    "    \n",
    "    # Reduce groups by doing union for groups having jaccard distance under threshold\n",
    "    df_reduced = recompute_groups(df,[\"period\",\"property_values\"],jaccard_threshold) \n",
    "    df_reduced.append({\"user_ids\":tuple(i for i in range(10000)),\"groups_ids\":[0],\"property_values\":\"O_M\",\"period\":\"2000-03-01\"},ignore_index=True)\n",
    "    print(f\"Reduced groups for{input_name}\")\n",
    "    \n",
    "    # Merge groups of consecutive periods \n",
    "    print(f\"Interaction computed for {input_name}\")\n",
    "    compute_groups_interactions(df_reduced,input_name)\n",
    "   \n",
    "    \n",
    "# [groups_interactions(i.split(\"/\")[1]) for i in a[5:]]\n",
    "a = groups_interactions(\"M-5-[5-50000]-[user_gender]-lcm.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for echarts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_links(x):\n",
    "    res = []\n",
    "    for i in x[0]:\n",
    "        for idx in range(len(i)-1):\n",
    "            res.append([i[idx],i[idx+1],x[\"index\"]])\n",
    "    return res\n",
    "\n",
    "def sankey_preprocessing(input_file,stats_folder='plots/stats',links_folder=\"plots/links\",groups_folder='plots/groups',demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"]):\n",
    "    users = pd.read_csv(\"datasets/Total/users.csv\",sep=\";\")   \n",
    "    df = read_lcm_output_total(inputut_file)\n",
    "#     df = df[df.property_values ==\"M\"]\n",
    "     # stats \n",
    "    file = f'{stats_folder}/{input_file}'\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    _df = mlb.fit_transform(df.user_ids.tolist()).astype(bool)\n",
    "    _df = pd.DataFrame(_df.toarray(),columns=mlb.classes_)\n",
    "\n",
    "    e = _df.sum()\n",
    "    _df = _df[e[e>3].index]\n",
    "    \n",
    "    _df  = _df.T.apply(lambda x : np.where(x)[0],axis=1)\n",
    "\n",
    "    e = _df.to_frame()[0].apply(lambda x: tuple(list(z) for idx,z in groupby(x,lambda y: df.iloc[y].period)))\n",
    "    \n",
    "    e = e[e.apply(lambda x:len(x))>5]\n",
    "    \n",
    "#     demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"]\n",
    "#     stats = {}\n",
    "    \n",
    "#     for i in demographics:\n",
    "#         b = a.groupby(i).apply(lambda x: {\"name\":x[i].unique()[0],\"value\":x.CUST_ID.shape[0],\"users\":\",\".join(str(i) for i in x.CUST_ID)}).values\n",
    "#         stats[i] = b.tolist()\n",
    "#     pd.DataFrame(stats).to_csv(file)\n",
    "\n",
    "    # links \n",
    "    file = f'{links_folder}/{input_file}'\n",
    "    e = e.apply(lambda x : list(product(*x)))\n",
    "    e = pd.DataFrame(e)\n",
    "    links = e.reset_index().apply(format_links,axis=1).sum()\n",
    "    \n",
    "    links = pd.DataFrame(links)\n",
    "    links = links.drop_duplicates()\n",
    "    links.columns = [\"source\",\"target\",\"user_id\"]\n",
    "    links.groupby([\"source\",\"target\"])[\"user_id\"].apply(lambda x: ','.join(str(i) for i in x)).to_frame().to_csv(file)\n",
    "    \n",
    "    # Stats  \n",
    "    file = f'plots/stats/{input_file}'\n",
    "    users_stats = links[[\"user_id\"]].drop_duplicates().merge(users,left_on=\"user_id\",right_on=\"CUST_ID\")[users.columns]\n",
    "    stats = {}\n",
    "    for i in demographics:\n",
    "        b = users_stats.groupby(i).apply(lambda x: {\"name\":x[i].unique()[0],\"value\":x.CUST_ID.shape[0],\"users\":\",\".join(str(i) for i in x.CUST_ID)}).values\n",
    "        stats[i] = b.tolist()\n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "  \n",
    "    # Users\n",
    "    file = f'plots/users/{input_file}'\n",
    "    users_stats.to_csv(file)\n",
    "    \n",
    "    file = f'{groups_folder}/{input_file}'\n",
    "    # filter groups to the ones appearing in the links\n",
    "    df_reduced_filtred = df.loc[np.unique(np.union1d(links.source.unique(),links.target.unique()))].dropna()\n",
    "    df_reduced_filtred['depth'] = le.fit_transform(df_reduced_filtred.period)/df_reduced_filtred.shape[0]\n",
    "    df_reduced_filtred['size'] = df_reduced_filtred.user_ids.apply(lambda x : len(x))\n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    return df_reduced_filtred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcm_output_total(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z.replace('\"',\"\")) for z in x[1:-1].split(\",\") if z != \"\"]))\n",
    "    return df\n",
    "\n",
    "df = read_lcm_output_total('M-5-[2-5000]-[SEX]-lcm.out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ids</th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "      <th>period</th>\n",
       "      <th>property_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[519495, 520696, 528218, 529470, 533033, 58238...</td>\n",
       "      <td>11</td>\n",
       "      <td>13600075 6026</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[187912, 274183, 390331, 431037, 469899, 51201...</td>\n",
       "      <td>11</td>\n",
       "      <td>4190175 19419902</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[144075, 428515, 497218, 524779, 584635, 651557]</td>\n",
       "      <td>6</td>\n",
       "      <td>7476355 7445935</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[286240, 336929, 359880, 584635, 740226]</td>\n",
       "      <td>5</td>\n",
       "      <td>5461018 7445935</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[393518, 478153, 522436, 529454, 529463, 54185...</td>\n",
       "      <td>8</td>\n",
       "      <td>6033 6026</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101207</th>\n",
       "      <td>[441811, 479778, 513416, 570510, 1209550]</td>\n",
       "      <td>5</td>\n",
       "      <td>4461002 4756741</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101208</th>\n",
       "      <td>[113854, 171050, 664713, 1077838, 1237929]</td>\n",
       "      <td>5</td>\n",
       "      <td>11421001 11462027</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101209</th>\n",
       "      <td>[124875, 235613, 813046, 971143, 978909, 1037289]</td>\n",
       "      <td>6</td>\n",
       "      <td>11430044 11421002</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101210</th>\n",
       "      <td>[122586, 156442, 326976, 449825, 958235]</td>\n",
       "      <td>5</td>\n",
       "      <td>11430218 11421002</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101211</th>\n",
       "      <td>[231378, 289550, 568551, 720928, 924132]</td>\n",
       "      <td>5</td>\n",
       "      <td>11461004 11421002</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101212 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 user_ids  support  \\\n",
       "0       [519495, 520696, 528218, 529470, 533033, 58238...       11   \n",
       "1       [187912, 274183, 390331, 431037, 469899, 51201...       11   \n",
       "2        [144075, 428515, 497218, 524779, 584635, 651557]        6   \n",
       "3                [286240, 336929, 359880, 584635, 740226]        5   \n",
       "4       [393518, 478153, 522436, 529454, 529463, 54185...        8   \n",
       "...                                                   ...      ...   \n",
       "101207          [441811, 479778, 513416, 570510, 1209550]        5   \n",
       "101208         [113854, 171050, 664713, 1077838, 1237929]        5   \n",
       "101209  [124875, 235613, 813046, 971143, 978909, 1037289]        6   \n",
       "101210           [122586, 156442, 326976, 449825, 958235]        5   \n",
       "101211           [231378, 289550, 568551, 720928, 924132]        5   \n",
       "\n",
       "                  itemsets     period property_values  \n",
       "0            13600075 6026 2017-03-01               F  \n",
       "1         4190175 19419902 2017-03-01               F  \n",
       "2          7476355 7445935 2017-03-01               F  \n",
       "3          5461018 7445935 2017-03-01               F  \n",
       "4                6033 6026 2017-03-01               F  \n",
       "...                    ...        ...             ...  \n",
       "101207     4461002 4756741 2019-10-01               M  \n",
       "101208   11421001 11462027 2019-10-01               M  \n",
       "101209   11430044 11421002 2019-10-01               M  \n",
       "101210   11430218 11421002 2019-10-01               M  \n",
       "101211   11461004 11421002 2019-10-01               M  \n",
       "\n",
       "[101212 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputut_file = \"2M-5-[2-5000]-[DEPARTEMENT]-lcm.out\"\n",
    "g = sankey_preprocessing(inputut_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DEPARTEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108938</td>\n",
       "      <td>M</td>\n",
       "      <td>50-65</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110899</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114666</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118478</td>\n",
       "      <td>M</td>\n",
       "      <td>50-65</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123777</td>\n",
       "      <td>M</td>\n",
       "      <td>50-65</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1167207</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1168767</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1171591</td>\n",
       "      <td>M</td>\n",
       "      <td>50-65</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1198352</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1205586</td>\n",
       "      <td>M</td>\n",
       "      <td>&lt;35</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CUST_ID SEX    AGE DEPARTEMENT\n",
       "0    108938   M  50-65          59\n",
       "1    110899   M  35-49          59\n",
       "2    114666   M  35-49          59\n",
       "3    118478   M  50-65          59\n",
       "4    123777   M  50-65          59\n",
       "..      ...  ..    ...         ...\n",
       "61  1167207   M  35-49          59\n",
       "62  1168767   M  35-49          59\n",
       "63  1171591   M  50-65          59\n",
       "64  1198352   M  35-49          59\n",
       "65  1205586   M    <35          62\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"datasets/Total/users.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>171</td>\n",
       "      <td>108938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>195</td>\n",
       "      <td>108938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>201</td>\n",
       "      <td>108938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201</td>\n",
       "      <td>213</td>\n",
       "      <td>108938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213</td>\n",
       "      <td>221</td>\n",
       "      <td>108938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788983</th>\n",
       "      <td>178</td>\n",
       "      <td>197</td>\n",
       "      <td>1205586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788984</th>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>1205586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788985</th>\n",
       "      <td>205</td>\n",
       "      <td>212</td>\n",
       "      <td>1205586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788986</th>\n",
       "      <td>212</td>\n",
       "      <td>224</td>\n",
       "      <td>1205586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788987</th>\n",
       "      <td>224</td>\n",
       "      <td>232</td>\n",
       "      <td>1205586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source  target  user_id\n",
       "0          150     171   108938\n",
       "1          171     195   108938\n",
       "2          195     201   108938\n",
       "3          201     213   108938\n",
       "4          213     221   108938\n",
       "...        ...     ...      ...\n",
       "788983     178     197  1205586\n",
       "788984     197     205  1205586\n",
       "788985     205     212  1205586\n",
       "788986     212     224  1205586\n",
       "788987     224     232  1205586\n",
       "\n",
       "[1759 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = g.merge(users,left_on=\"user_id\",right_on=\"CUST_ID\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEPARTEMENT': [{'value': '59',\n",
       "   'size': 26,\n",
       "   'users': '108938,110899,114666,118478,123777,127790,133892,187833,235297,244827,270220,292347,314647,368080,403445,421137,425954,427096,427250,464331,483533,602580,607784,612824,616689,739860'},\n",
       "  {'value': '62', 'size': 3, 'users': '156634,460228,552846'},\n",
       "  {'value': '78',\n",
       "   'size': 13,\n",
       "   'users': '263913,294115,428202,468837,471775,519469,519885,555714,584447,619437,715341,719763,735292'}],\n",
       " 'SEX': [{'value': 'M',\n",
       "   'size': 42,\n",
       "   'users': '108938,110899,114666,118478,123777,127790,133892,156634,187833,235297,244827,263913,270220,292347,294115,314647,368080,403445,421137,425954,427096,427250,428202,460228,464331,468837,471775,483533,519469,519885,552846,555714,584447,602580,607784,612824,616689,619437,715341,719763,735292,739860'}],\n",
       " 'AGE': [{'value': '35-49',\n",
       "   'size': 19,\n",
       "   'users': '110899,114666,156634,244827,292347,294115,421137,425954,427096,427250,460228,468837,483533,519885,555714,607784,616689,619437,719763'},\n",
       "  {'value': '50-65',\n",
       "   'size': 15,\n",
       "   'users': '108938,118478,123777,127790,133892,187833,235297,263913,270220,368080,428202,464331,471775,584447,715341'},\n",
       "  {'value': '<35',\n",
       "   'size': 7,\n",
       "   'users': '314647,403445,552846,602580,612824,735292,739860'},\n",
       "  {'value': '>65', 'size': 1, 'users': '519469'}]}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stats.json', 'w') as outfile:\n",
    "    json.dump(stats, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",0,1,2,3\r\n",
      "0,\"{'value': '59', 'size': 26, 'users': '108938,110899,114666,118478,123777,127790,133892,187833,235297,244827,270220,292347,314647,368080,403445,421137,425954,427096,427250,464331,483533,602580,607784,612824,616689,739860'}\",\"{'value': '62', 'size': 3, 'users': '156634,460228,552846'}\",\"{'value': '78', 'size': 13, 'users': '263913,294115,428202,468837,471775,519469,519885,555714,584447,619437,715341,719763,735292'}\",\r\n",
      "1,\"{'value': 'M', 'size': 42, 'users': '108938,110899,114666,118478,123777,127790,133892,156634,187833,235297,244827,263913,270220,292347,294115,314647,368080,403445,421137,425954,427096,427250,428202,460228,464331,468837,471775,483533,519469,519885,552846,555714,584447,602580,607784,612824,616689,619437,715341,719763,735292,739860'}\",,,\r\n",
      "2,\"{'value': '35-49', 'size': 19, 'users': '110899,114666,156634,244827,292347,294115,421137,425954,427096,427250,460228,468837,483533,519885,555714,607784,616689,619437,719763'}\",\"{'value': '50-65', 'size': 15, 'users': '108938,118478,123777,127790,133892,187833,235297,263913,270220,368080,428202,464331,471775,584447,715341'}\",\"{'value': '<35', 'size': 7, 'users': '314647,403445,552846,602580,612824,735292,739860'}\",\"{'value': '>65', 'size': 1, 'users': '519469'}\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
