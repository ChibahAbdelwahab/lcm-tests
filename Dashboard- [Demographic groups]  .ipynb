{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core import display as ICD\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer\n",
    "from itertools import groupby, product\n",
    "import json\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcm_output(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z) for z in x.split(\" \") if z != \"\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_lcm_output_total(input_name,folder=\"lcm_results\"):\n",
    "    \"\"\"Read and restructure LCM output file,rename columns output a df \"\"\"\n",
    "    file = f'{folder}/{input_name}'\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    df.columns = [\"user_ids\",\"support\",\"itemsets\",\"period\",\"property_values\"]\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"user_ids\"] = df.user_ids.apply(lambda x : np.array([int(z.replace('\"',\"\")) for z in x[1:-1].split(\",\") if z != \"\"]))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for echarts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_links(x):\n",
    "    res = []\n",
    "    for i in x[0]:\n",
    "        for idx in range(len(i)-1):\n",
    "            res.append([i[idx],i[idx+1],x[\"index\"]])\n",
    "    return res\n",
    "\n",
    "def make_links(e,index):\n",
    "    \"\"\"Product of groups ids for each two consecutive groups periods\"\"\"\n",
    "    prev = e[0]\n",
    "    for i in e[1:]:\n",
    "        yield from product(prev,i,[index])\n",
    "        prev = i\n",
    "\n",
    "def extract_demographics(input_file):\n",
    "    demographics = re.findall(\"\\[([A-Z|a-z|_]+),?([A-Z|a-z|_]+)?\\]\",input_file)[0]\n",
    "    return  [i for i in demographics if i !=\"\"]\n",
    "    \n",
    "def sankey_preprocessing(input_file,stats_folder='plots/stats',links_folder=\"plots/links\",groups_folder='plots/groups',users_demographics = [\"DEPARTEMENT\",\"SEX\",\"AGE\"],groups_demographics=[\"STATION_MGT_TYPE\",\"DEPARTEMENT\"],users_consecutive_apparition=3):\n",
    "#     if \"M-10-[2-5000]-[AGE]-lcm.out\" in input_file :\n",
    "#         return\n",
    "    \n",
    "    demographics = extract_demographics(input_file)\n",
    "    users = pd.read_csv(\"datasets/Total/users.csv\",sep=\";\")\n",
    "    df = read_lcm_output_total(input_file).sort_values(\"period\").reset_index(drop=True)\n",
    "    \n",
    "    file = f'plots/links/{input_file}'\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    _df = mlb.fit_transform(df.user_ids.tolist()).astype(bool)\n",
    "    _df = pd.DataFrame(_df.toarray(),columns=mlb.classes_)\n",
    "    \n",
    "    e = _df.sum()\n",
    "    _df = _df[e[e>1].index]\n",
    "    _df  = _df.T.apply(lambda x : np.where(x)[0],axis=1)\n",
    "    e = _df.to_frame()[0].apply(lambda x: list(list(z) for idx,z in groupby(x,lambda y: df.iloc[y].period)))\n",
    "    e = e[e.apply(lambda x:len(x))>users_consecutive_apparition]\n",
    "    \n",
    "    res = []\n",
    "    e.to_frame().reset_index().apply(lambda x: [res.append(i) for i in make_links(x[0],x[\"index\"])],axis=1)\n",
    "    links = pd.DataFrame(res)\n",
    "    links.columns = [\"source\",\"target\",\"user_id\"]\n",
    "    links.groupby([\"source\",\"target\"])[\"user_id\"].apply(lambda x: ','.join(str(i) for i in x)).to_frame().to_csv(file)\n",
    "\n",
    "    # Users demographics stats  \n",
    "    file = f'plots/stats/users/{input_file}'\n",
    "    stats = {}\n",
    "    users_stats = links[[\"user_id\"]].drop_duplicates().merge(users,left_on=\"user_id\",right_on=\"CUST_ID\")[users.columns]\n",
    "    for i in users_demographics:\n",
    "        b = users_stats.groupby(i).apply(lambda x: {\"name\":x[i].unique()[0],\"value\":x.CUST_ID.shape[0],\"users\":\",\".join(str(i) for i in x.CUST_ID)}).values\n",
    "        stats[i] = b.tolist()\n",
    "        \n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "  \n",
    "    \n",
    "    # Users\n",
    "    file = f'plots/users/{input_file}'\n",
    "    users_stats.to_csv(file)\n",
    "    \n",
    "    # filter groups to the ones appearing in the links\n",
    "    file = f'{groups_folder}/{input_file}'\n",
    "    df_reduced_filtred = df.loc[np.unique(np.union1d(links.source.unique(),links.target.unique()))].dropna()\n",
    "    df_reduced_filtred['depth'] = le.fit_transform(df_reduced_filtred.period)/df_reduced_filtred.period.nunique()\n",
    "    df_reduced_filtred['size'] = df_reduced_filtred.user_ids.apply(lambda x : len(x))\n",
    "    if len(demographics)==1:\n",
    "        df_reduced_filtred[demographics[0]]= df_reduced_filtred.property_values\n",
    "    else:\n",
    "        df_reduced_filtred[demographics]= df_reduced_filtred.property_values.str.split(\"_\",expand=True)\n",
    "        \n",
    "    # Encoding items to their initial ID + adding names\n",
    "    items = pd.read_csv(\"datasets/Total/items.csv\",encoding=\"latin\",sep=\";\")\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load(f'plots/encoders/{input_file}.npy')\n",
    "    df_reduced_filtred[\"itemsets_name\"] = df_reduced_filtred[\"itemsets\"].apply(lambda x : encoder.inverse_transform([int(i) for i in x.split()]))\n",
    "    z = df_reduced_filtred[\"itemsets_name\"] .apply(lambda x : [items[items.ARTICLE_ID==i].DESCRIPTION.tolist() for i in x ]).to_frame()\n",
    "    df_reduced_filtred[\"itemsets_name\"] = z.apply(lambda x : \"; \".join([i for i in x[0][0]]),axis=1)\n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    \n",
    "    df_reduced_filtred.to_csv(file)\n",
    "    \n",
    "    # Groups demographics stats \n",
    "    file = f'plots/stats/groups/{input_file}'\n",
    "    stats = {}\n",
    "    for i in np.intersect1d(groups_demographics,demographics):\n",
    "        b = df_reduced_filtred.groupby(i).apply(lambda x : {\"name\":x[i].unique()[0],\"value\":x.index.shape[0],\"groups\":\",\".join(str(i) for i in x.index)}).values\n",
    "        stats[i]=str(b.tolist())\n",
    "        \n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(stats, outfile)\n",
    "    \n",
    "    \n",
    "    print(\"Done\",input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9M-5-[1-2001]-[a]-lcm.out ['a']\n",
      "Done 9M-5-[1-2001]-[a]-lcm.out\n"
     ]
    }
   ],
   "source": [
    "a = !ls lcm_results/\n",
    "for i in [\"9M-5-[1-2001]-[a]-lcm.out\"]:\n",
    "    print(i,extract_demographics(i))\n",
    "    try:\n",
    "        e = sankey_preprocessing(i,users_consecutive_apparition=2)\n",
    "    except Exception as e:\n",
    "        print(\"Error\",i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
